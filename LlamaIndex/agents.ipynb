{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxxqRNIiPl3z",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Agents in LlamaIndex\n",
    "\n",
    "This notebook is part of the [Hugging Face Agents Course](https://www.hf.co/learn/agents-course), a free Course from beginner to expert, where you learn to build Agents.\n",
    "\n",
    "![Agents course share](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png)\n",
    "\n",
    "## Let's install the dependencies\n",
    "\n",
    "We will install the dependencies for this unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LlZfImAEPl31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Users/ron/Documents/github/myenv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index llama-index-vector-stores-chroma llama-index-llms-huggingface-api llama-index-embeddings-huggingface -U -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mk26JX_fPl31"
   },
   "source": [
    "And, let's log in to Hugging Face to use serverless Inference APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Vet1-gLzPl31"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba145c21f2b04c3eb0873e1b8ef14f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ap4oB7ajPl31",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Initialising agents\n",
    "\n",
    "Let's start by initialising an agent. We will use the basic `AgentWorkflow` class to create an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SoTjzwkePl31"
   },
   "outputs": [],
   "source": [
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "from llama_index.core.agent.workflow import AgentWorkflow, ToolCallResult, AgentStream\n",
    "\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two numbers\"\"\"\n",
    "    return a - b\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def divide(a: int, b: int) -> int:\n",
    "    \"\"\"Divide two numbers\"\"\"\n",
    "    return a / b\n",
    "\n",
    "\n",
    "llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\", provider=\"auto\")\n",
    "#llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\", provider=\"auto\")\n",
    "\n",
    "agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[subtract, multiply, divide, add],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUMuRvWqPl32"
   },
   "source": [
    "Then, we can run the agent and get the response and reasoning behind the tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1KEVzqPJPl32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: add\n",
      "Action Input: {\"a\": 2, \"b\": 2}\n",
      "\n",
      "Called tool:  add {'a': 2, 'b': 2} => 4\n",
      "Thought: Now I need to multiply the result by 3.\n",
      "Action: multiply\n",
      "Action Input: {'a': 4, 'b': 3}\n",
      "Called tool:  multiply {'a': 4, 'b': 3} => 12\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: (2 + 2) * 3 = 12"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='(2 + 2) * 3 = 12')]), structured_response=None, current_agent_name='Agent', raw=ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role=None, content='', tool_call_id=None, tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1753563735953, id='BMZKPq', model='Qwen/Qwen2.5-Coder-32B-Instruct', system_fingerprint=None, usage=None, object='chat.completion.chunk'), tool_calls=[ToolCallResult(tool_name='add', tool_kwargs={'a': 2, 'b': 2}, tool_id='d42f0d5d-b353-4b92-acee-d0aeadc470c2', tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text='4')], tool_name='add', raw_input={'args': (), 'kwargs': {'a': 2, 'b': 2}}, raw_output=4, is_error=False), return_direct=False), ToolCallResult(tool_name='multiply', tool_kwargs={'a': 4, 'b': 3}, tool_id='1d25677a-adf5-4f40-b8e5-4a7909d98866', tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text='12')], tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 4, 'b': 3}}, raw_output=12, is_error=False), return_direct=False)], retry_messages=[])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler = agent.run(\"What is (2 + 2) * 3?\")\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "    elif isinstance(ev, AgentStream):  # showing the thought process\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4XDsdC0Pl32"
   },
   "source": [
    "In a similar fashion, we can pass state and context to the agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Z0jzMKmAPl32",
    "outputId": "e80fa345-58bc-4dcf-e5f9-7ddaef141a16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='Your name is Bob.')]), structured_response=None, current_agent_name='Agent', raw=ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role=None, content='', tool_call_id=None, tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1753039245364, id='fqfziv', model='Qwen/Qwen2.5-Coder-32B-Instruct', system_fingerprint=None, usage=None, object='chat.completion.chunk'), tool_calls=[], retry_messages=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.workflow import Context\n",
    "# stateless\n",
    "response = await agent.run(\"What is 2 times 2?\")\n",
    "\n",
    "ctx = Context(agent)\n",
    "\n",
    "response = await agent.run(\"My name is Bob.\", ctx=ctx)\n",
    "response = await agent.run(\"What was my name again?\", ctx=ctx)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Bob.\n"
     ]
    }
   ],
   "source": [
    "# stateless\n",
    "response = await agent.run(\"What is 2 times 2?\")\n",
    "\n",
    "# remembering state\n",
    "from llama_index.core.workflow import Context\n",
    "\n",
    "ctx = Context(agent)\n",
    "\n",
    "response = await agent.run(\"My name is Bob.\", ctx=ctx)\n",
    "response = await agent.run(\"What was my name again?\", ctx=ctx)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jU-REqMHPl32"
   },
   "source": [
    "## Creating RAG Agents with QueryEngineTools\n",
    "\n",
    "Let's now re-use the `QueryEngine` we defined in the [previous unit on tools](/tools.ipynb) and convert it into a `QueryEngineTool`. We will pass it to the `AgentWorkflow` class to create a RAG agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wZE7mucQPl32"
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "# Create a vector store\n",
    "db = chromadb.PersistentClient(path=\"./alfred_chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"alfred\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "# Create a query engine\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\", provider=\"auto\")\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, embed_model=embed_model\n",
    ")\n",
    "query_engine = index.as_query_engine(llm=llm)\n",
    "query_engine_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"personas\",\n",
    "    description=\"descriptions for various types of personas\",\n",
    "    return_direct=False,\n",
    ")\n",
    "\n",
    "# Create a RAG agent\n",
    "query_engine_agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[query_engine_tool],\n",
    "    llm=llm,\n",
    "    system_prompt=\"You are a helpful assistant that has access to a database containing persona descriptions. \",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-Z_YCYnPl33"
   },
   "source": [
    "And, we can once more get the response and reasoning behind the tool calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "iCeqoGLZPl33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: personas\n",
      "Action Input: {\"input\": \"science fiction\"}\n",
      "Called tool:  personas {'input': 'science fiction'} => science fiction\n",
      "Thought: The observation provided does not seem to contain specific persona descriptions related to science fiction. I need to refine my approach to get more detailed and relevant information about personas in the context of science fiction.\n",
      "Action: personas\n",
      "Action Input: {'input': 'descriptions of personas in science fiction'}\n",
      "Called tool:  personas {'input': 'descriptions of personas in science fiction'} => Descriptions of personas in science fiction often delve into detailed narratives that explore various aspects of human nature, societal structures, and technological advancements. These personas can range from complex, morally ambiguous characters to idealized heroes or villains, each contributing to the thematic depth of the story. They might inhabit futuristic worlds, alternate realities, or distant planets, facing challenges that test their resilience, ethics, and adaptability. Through these characters, science fiction often examines themes such as the impact of technology on society, the consequences of human actions, and the quest for knowledge and survival.\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Descriptions of personas in science fiction often delve into detailed narratives that explore various aspects of human nature, societal structures, and technological advancements. These personas can range from complex, morally ambiguous characters to idealized heroes or villains, each contributing to the thematic depth of the story. They might inhabit futuristic worlds, alternate realities, or distant planets, facing challenges that test their resilience, ethics, and adaptability. Through these characters, science fiction often examines themes such as the impact of technology on society, the consequences of human actions, and the quest for knowledge and survival."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='Descriptions of personas in science fiction often delve into detailed narratives that explore various aspects of human nature, societal structures, and technological advancements. These personas can range from complex, morally ambiguous characters to idealized heroes or villains, each contributing to the thematic depth of the story. They might inhabit futuristic worlds, alternate realities, or distant planets, facing challenges that test their resilience, ethics, and adaptability. Through these characters, science fiction often examines themes such as the impact of technology on society, the consequences of human actions, and the quest for knowledge and survival.')]), structured_response=None, current_agent_name='Agent', raw=ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role=None, content='', tool_call_id=None, tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1753039853691, id='MWRiSV', model='Qwen/Qwen2.5-Coder-32B-Instruct', system_fingerprint=None, usage=None, object='chat.completion.chunk'), tool_calls=[ToolCallResult(tool_name='personas', tool_kwargs={'input': 'science fiction'}, tool_id='8e882406-a2d8-497e-85c1-928c3214f278', tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text='science fiction')], tool_name='personas', raw_input={'input': 'science fiction'}, raw_output=Response(response='science fiction', source_nodes=[NodeWithScore(node=TextNode(id_='71b8d596-2ffd-4768-9cd6-71d5d3d9ea6a', embedding=None, metadata={'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_100.txt', 'file_name': 'persona_100.txt', 'file_type': 'text/plain', 'file_size': 107, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='feb8266f-c329-44fa-adf4-7128fb10083b', node_type='4', metadata={'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_100.txt', 'file_name': 'persona_100.txt', 'file_type': 'text/plain', 'file_size': 107, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, hash='b557254467acbcd3ddd4f0251d1cc269f323ace5ad595ffbc6dc7dc25ea9ccc2')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An environmental conservationist focused on wetland ecosystems and their role in mitigating climate change.', mimetype='text/plain', start_char_idx=0, end_char_idx=107, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.4254867322588287), NodeWithScore(node=TextNode(id_='abdeb127-aeb6-44d6-8080-f3c589435a1f', embedding=None, metadata={'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_0.txt', 'file_name': 'persona_0.txt', 'file_type': 'text/plain', 'file_size': 132, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='634da32b-7b6c-4446-beb3-5dd1436c5fe1', node_type='4', metadata={'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_0.txt', 'file_name': 'persona_0.txt', 'file_type': 'text/plain', 'file_size': 132, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, hash='3c20712ce05dedb0a1ecded1d057511b572dec466ad05c48ee2baf7e958af9ae')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='A local art historian and museum professional interested in 19th-century American art and the local cultural heritage of Cincinnati.', mimetype='text/plain', start_char_idx=0, end_char_idx=132, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.4215451370164642)], metadata={'71b8d596-2ffd-4768-9cd6-71d5d3d9ea6a': {'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_100.txt', 'file_name': 'persona_100.txt', 'file_type': 'text/plain', 'file_size': 107, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, 'abdeb127-aeb6-44d6-8080-f3c589435a1f': {'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_0.txt', 'file_name': 'persona_0.txt', 'file_type': 'text/plain', 'file_size': 132, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}}), is_error=False), return_direct=False), ToolCallResult(tool_name='personas', tool_kwargs={'input': 'descriptions of personas in science fiction'}, tool_id='49b80010-b3c2-44c1-9986-fdbd6e5f6925', tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text='Descriptions of personas in science fiction often delve into detailed narratives that explore various aspects of human nature, societal structures, and technological advancements. These personas can range from complex, morally ambiguous characters to idealized heroes or villains, each contributing to the thematic depth of the story. They might inhabit futuristic worlds, alternate realities, or distant planets, facing challenges that test their resilience, ethics, and adaptability. Through these characters, science fiction often examines themes such as the impact of technology on society, the consequences of human actions, and the quest for knowledge and survival.')], tool_name='personas', raw_input={'input': 'descriptions of personas in science fiction'}, raw_output=Response(response='Descriptions of personas in science fiction often delve into detailed narratives that explore various aspects of human nature, societal structures, and technological advancements. These personas can range from complex, morally ambiguous characters to idealized heroes or villains, each contributing to the thematic depth of the story. They might inhabit futuristic worlds, alternate realities, or distant planets, facing challenges that test their resilience, ethics, and adaptability. Through these characters, science fiction often examines themes such as the impact of technology on society, the consequences of human actions, and the quest for knowledge and survival.', source_nodes=[NodeWithScore(node=TextNode(id_='da6eafda-2673-4eb6-b04b-8b36ac6677b4', embedding=None, metadata={'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='5dc8de63-8225-4e77-85af-d72e4dfab534', node_type='4', metadata={'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, hash='0bf4fab5f05d53151c9c6ce763c13277035a7232aabca662a10a779c7daa0076')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An anthropologist or a cultural expert interested in the intricacies of Cypriot culture, history, and society, particularly someone who has spent considerable time researching and living in Cyprus to gain a deep understanding of its people, customs, and way of life.', mimetype='text/plain', start_char_idx=0, end_char_idx=266, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5530920384941381), NodeWithScore(node=TextNode(id_='41245876-726e-4063-8b3f-cd6515941040', embedding=None, metadata={'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_1001.txt', 'file_name': 'persona_1001.txt', 'file_type': 'text/plain', 'file_size': 157, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='6606c986-9c2b-4035-885a-197d6eed8322', node_type='4', metadata={'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_1001.txt', 'file_name': 'persona_1001.txt', 'file_type': 'text/plain', 'file_size': 157, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, hash='3fa17a468bc228e10bbf520f31a85fb2d05928fc8f747cf3844c18f7da09889e')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='A web developer or a web development student, likely in the early stages of their learning or career, with a strong focus on HTML, CSS, and website building.', mimetype='text/plain', start_char_idx=0, end_char_idx=157, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5492458137985679)], metadata={'da6eafda-2673-4eb6-b04b-8b36ac6677b4': {'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, '41245876-726e-4063-8b3f-cd6515941040': {'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_1001.txt', 'file_name': 'persona_1001.txt', 'file_type': 'text/plain', 'file_size': 157, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}}), is_error=False), return_direct=False)], retry_messages=[])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler = query_engine_agent.run(\n",
    "    \"Search the database for 'science fiction' and return some persona descriptions.\"\n",
    ")\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "    elif isinstance(ev, AgentStream):  # showing the thought process\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfYKw34fPl33"
   },
   "source": [
    "## Creating multi-agent systems\n",
    "\n",
    "We can also create multi-agent systems by passing multiple agents to the `AgentWorkflow` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HOES7RtgPl33"
   },
   "outputs": [],
   "source": [
    "from llama_index.core.agent.workflow import (\n",
    "    AgentWorkflow,\n",
    "    ReActAgent,\n",
    ")\n",
    "\n",
    "\n",
    "# Define some tools\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two numbers.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "\n",
    "# Create agent configs\n",
    "# NOTE: we can use FunctionAgent or ReActAgent here.\n",
    "# FunctionAgent works for LLMs with a function calling API.\n",
    "# ReActAgent works for any LLM.\n",
    "calculator_agent = ReActAgent(\n",
    "    name=\"calculator\",\n",
    "    description=\"Performs basic arithmetic operations\",\n",
    "    system_prompt=\"You are a calculator assistant. Use your tools for any math operation.\",\n",
    "    tools=[add, subtract],\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "query_agent = ReActAgent(\n",
    "    name=\"info_lookup\",\n",
    "    description=\"Looks up information about XYZ\",\n",
    "    system_prompt=\"Use your tool to query a RAG system to answer information about XYZ\",\n",
    "    tools=[query_engine_tool],\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# Create and run the workflow\n",
    "agent = AgentWorkflow(agents=[calculator_agent, query_agent], root_agent=\"calculator\")\n",
    "\n",
    "# Run the system\n",
    "handler = agent.run(user_msg=\"Can you add 5 and 3?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Lmtoome8Pl33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: add\n",
      "Action Input: {\"a\": 5, \"b\": 3}\n",
      "Called tool:  add {'a': 5, 'b': 3} => 8\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: 8"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='8')]), structured_response=None, current_agent_name='calculator', raw=ChatCompletionStreamOutput(choices=[ChatCompletionStreamOutputChoice(delta=ChatCompletionStreamOutputDelta(role=None, content='', tool_call_id=None, tool_calls=None), index=0, finish_reason=None, logprobs=None)], created=1753039972443, id='NiiC8E', model='Qwen/Qwen2.5-Coder-32B-Instruct', system_fingerprint=None, usage=None, object='chat.completion.chunk'), tool_calls=[ToolCallResult(tool_name='add', tool_kwargs={'a': 5, 'b': 3}, tool_id='0918e328-cee8-4434-b49c-65d95bf90761', tool_output=ToolOutput(blocks=[TextBlock(block_type='text', text='8')], tool_name='add', raw_input={'args': (), 'kwargs': {'a': 5, 'b': 3}}, raw_output=8, is_error=False), return_direct=False)], retry_messages=[])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "    elif isinstance(ev, AgentStream):  # showing the thought process\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
