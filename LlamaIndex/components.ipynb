{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wfQIVZOmCaP"
   },
   "source": [
    "# Components in LlamaIndex\n",
    "\n",
    "This notebook is part of the [Hugging Face Agents Course](https://www.hf.co/learn/agents-course), a free Course from beginner to expert, where you learn to build Agents.\n",
    "\n",
    "![Agents course share](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png)\n",
    "\n",
    "Alfred is hosting a party and needs to be able to find relevant information on personas that will be attending the party. Therefore, we will use a `QueryEngine` to index and search through a database of personas.\n",
    "\n",
    "## Let's install the dependencies\n",
    "\n",
    "We will install the dependencies for this unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TrOLLiyamCaR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Users/ron/Documents/github/myenv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index datasets llama-index-callbacks-arize-phoenix arize-phoenix llama-index-vector-stores-chroma llama-index-llms-huggingface-api llama-index-embeddings-huggingface -U -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (0.12.50)\n",
      "Requirement already satisfied: datasets in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (4.0.0)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5,>=0.4.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index) (0.4.12)\n",
      "Requirement already satisfied: llama-index-cli<0.5,>=0.4.2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index) (0.4.4)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.5,>=0.4.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index) (0.4.7)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5,>=0.4.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index) (0.4.11)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index) (0.7.10)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4,>=0.3.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index) (0.3.2)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4,>=0.3.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.6,>=0.5.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index) (0.5.3)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.50 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index) (0.12.50)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4,>=0.3.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: packaging in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: pandas in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from datasets) (0.33.4)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from datasets) (2025.3.0)\n",
      "Requirement already satisfied: filelock in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: openai>=1.14.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.97.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (1.6.0)\n",
      "Requirement already satisfied: platformdirs in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (4.3.7)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (3.2.1)\n",
      "Requirement already satisfied: sqlalchemy[asyncio]>=1.4.49 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (2.0.41)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (11.2.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (0.9.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (9.1.2)\n",
      "Collecting setuptools>=80.9.0\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (0.9.0)\n",
      "Requirement already satisfied: httpx in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (0.28.1)\n",
      "Requirement already satisfied: eval-type-backport<0.3,>=0.2.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (0.2.2)\n",
      "Requirement already satisfied: dataclasses-json in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (0.6.7)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (2.2.0)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (1.2.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (1.2.18)\n",
      "Requirement already satisfied: aiosqlite in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (0.21.0)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (1.0.8)\n",
      "Requirement already satisfied: wrapt in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (1.17.2)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (2.11.7)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13,>=0.12.50->llama-index) (1.1.0)\n",
      "Requirement already satisfied: jinja2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.50->llama-index) (3.1.6)\n",
      "Requirement already satisfied: griffe in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.50->llama-index) (1.7.3)\n",
      "Requirement already satisfied: llama-cloud==0.1.32 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.32)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-cloud==0.1.32->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from httpx->llama-index-core<0.13,>=0.12.50->llama-index) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from httpx->llama-index-core<0.13,>=0.12.50->llama-index) (3.10)\n",
      "Requirement already satisfied: anyio in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from httpx->llama-index-core<0.13,>=0.12.50->llama-index) (4.9.0)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from httpcore==1.*->httpx->llama-index-core<0.13,>=0.12.50->llama-index) (0.16.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: pypdf<6,>=5.1.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (5.8.0)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (0.7.1)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (4.13.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.7)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.43)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.50->llama-index) (0.3.0)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.43 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.43)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-cloud-services>=0.6.43->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (8.1.8)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-cloud-services>=0.6.43->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.0)\n",
      "Requirement already satisfied: joblib in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from nltk>3.8.1->llama-index) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
      "Requirement already satisfied: sniffio in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from anyio->httpx->llama-index-core<0.13,>=0.12.50->llama-index) (1.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.50->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.50->llama-index) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from pydantic>=2.8.0->llama-index-core<0.13,>=0.12.50->llama-index) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13,>=0.12.50->llama-index) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13,>=0.12.50->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from dataclasses-json->llama-index-core<0.13,>=0.12.50->llama-index) (3.26.1)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.50->llama-index) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.50->llama-index) (3.0.2)\n",
      "Installing collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 58.0.4\n",
      "    Not uninstalling setuptools at /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages, outside environment /Users/ron/Documents/github/myenv\n",
      "    Can't uninstall 'setuptools'. No files were found to uninstall.\n",
      "Successfully installed setuptools-80.9.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Users/ron/Documents/github/myenv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "zsh:1: command not found: llama-index-callbacks-arize-phoenix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: llama-index-vector-stores-chroma\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: llama-index-llms-huggingface-api\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: llama-index-embeddings-huggingface\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index datasets \n",
    "!llama-index-callbacks-arize-phoenix arize-phoenix \n",
    "!llama-index-vector-stores-chroma \n",
    "!llama-index-llms-huggingface-api \n",
    "!llama-index-embeddings-huggingface -U -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rwgo6bCxmCaS"
   },
   "source": [
    "And, let's log in to Hugging Face to use serverless Inference APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cfkJi7NQmCaS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ron/Documents/github/myenv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45dae14c84d54c10a73e08727e60a8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCoZecYNmCaS"
   },
   "source": [
    "## Create a `QueryEngine` for retrieval augmented generation\n",
    "\n",
    "### Setting up the persona database\n",
    "\n",
    "We will be using personas from the [dvilasuero/finepersonas-v0.1-tiny dataset](https://huggingface.co/datasets/dvilasuero/finepersonas-v0.1-tiny). This dataset contains 5K personas that will be attending the party!\n",
    "\n",
    "Let's load the dataset and store it as files in the `data` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ltdkJTo2mCaS"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8d57c10d6442dfba407dbceed08f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/618 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a929dece97a441b3b96c45cd25325cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/35.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ea63b2d03b45c19e462c2f7323194d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "dataset = load_dataset(path=\"dvilasuero/finepersonas-v0.1-tiny\", split=\"train\")\n",
    "\n",
    "Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
    "for i, persona in enumerate(dataset):\n",
    "    with open(Path(\"data\") / f\"persona_{i}.txt\", \"w\") as f:\n",
    "        f.write(persona[\"persona\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2Sn7RWemCaS"
   },
   "source": [
    "Awesome, now we have a local directory with all the personas that will be attending the party, we can load and index!\n",
    "\n",
    "### Loading and embedding persona documents\n",
    "\n",
    "We will use the `SimpleDirectoryReader` to load the persona descriptions from the `data` directory. This will return a list of `Document` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qgLmB5q6mCaS",
    "outputId": "2f2b9aa7-97c7-4fc8-c7e3-c9995f3c4530"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "reader = SimpleDirectoryReader(input_dir=\"data\")\n",
    "documents = reader.load_data()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A local art historian and museum professional interested in 19th-century American art and the local cultural heritage of Cincinnati.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].text_resource.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'634da32b-7b6c-4446-beb3-5dd1436c5fe1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='634da32b-7b6c-4446-beb3-5dd1436c5fe1', embedding=None, metadata={'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_0.txt', 'file_name': 'persona_0.txt', 'file_type': 'text/plain', 'file_size': 132, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='A local art historian and museum professional interested in 19th-century American art and the local cultural heritage of Cincinnati.', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-eOBawTmCaT"
   },
   "source": [
    "Now we have a list of `Document` objects, we can use the `IngestionPipeline` to create nodes from the documents and prepare them for the `QueryEngine`. We will use the `SentenceSplitter` to split the documents into smaller chunks and the `HuggingFaceEmbedding` to embed the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "JdOOKA7OmCaT",
    "outputId": "99db5381-5450-41a2-f744-2877be622f46"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c46d89225774952accfb0dd1de80dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8835d52206e94cb0b8a3b80ff42f24e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b70f3a659f43ed85bce62e27b8c4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354e40b2374a4fdfadafb7facd153725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cf0985a6b446de99b6318decb34059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab1f5dfc1e44e3c9e38527321ec8d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d3f47969314d818ea95a3848289186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4248b4c04ec43639f4c6aa87d8b9de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1060a2337f40409b0acea04f104ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e868c4418a2f47d2b6437ebda7493cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb17dcb9acb146cb9604e17e89c7de17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "# create the pipeline with transformations\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(),\n",
    "        HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# run the pipeline sync or async\n",
    "nodes = await pipeline.arun(documents=documents[:10])\n",
    "#nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='15adb2fb-e11a-4975-9fb4-aa2d0646bc27', embedding=[-0.032320331782102585, -0.001098306616768241, 0.034757986664772034, 0.0065787420608103275, 0.0028960176277905703, -0.03161643072962761, 0.013406763784587383, 0.01667366921901703, -0.03175484016537666, -0.05845069885253906, 0.009463371708989143, -0.02386711910367012, -0.01347836572676897, 0.037097904831171036, -0.01255935337394476, -0.0039766267873346806, 0.0027470597997307777, 0.07235545665025711, 0.0005140079301781952, 0.010244878940284252, 0.018759561702609062, -0.06781893968582153, 0.05165273696184158, -0.024823851883411407, -0.02610919438302517, 0.011951661668717861, 0.0066216145642101765, -0.016723517328500748, -0.013858274556696415, -0.1329323649406433, -0.02920284867286682, 0.02286929078400135, -0.002473181812092662, 0.01840539649128914, 0.056015826761722565, 0.01120830699801445, -0.01652495563030243, 0.05420403182506561, -0.008843641728162766, 0.02515135146677494, 0.03171534463763237, 0.00745045579969883, -0.022080490365624428, 0.0665370374917984, 0.06443892419338226, -0.02006014809012413, -0.00575298210605979, -0.010122008621692657, 0.010937591083347797, 0.0001970896846614778, 0.020951449871063232, -0.0072320373728871346, -0.05150796100497246, 0.004339268896728754, -0.0004690919304266572, 0.08928204327821732, 0.08858955651521683, 0.04210084304213524, -0.014379072934389114, 0.03771374374628067, 0.06501693278551102, 0.039119262248277664, -0.18768979609012604, 0.04373522475361824, 0.011354499496519566, 0.010460352525115013, -0.07621648907661438, -0.011470954865217209, -0.0021874678786844015, -0.033758074045181274, -0.03613447770476341, -0.002284746151417494, -0.05626000836491585, 0.008608353324234486, 0.043884675949811935, -0.06438270211219788, 0.035262130200862885, 0.004011895973235369, -0.054947659373283386, 0.008295263163745403, 0.021069705486297607, -0.0214211568236351, -0.02686631679534912, -0.0113696763291955, -0.017164459452033043, 0.03334800526499748, -0.0006557320593856275, 0.016505267471075058, -0.017663463950157166, -0.02460905723273754, -0.017656998708844185, -0.056368861347436905, 0.0645972266793251, 0.00871321652084589, -0.03240163251757622, -0.027755416929721832, 0.022077487781643867, 0.05043201521039009, 0.0014609971549361944, 0.43632227182388306, -0.01893646828830242, -0.006810658145695925, 0.011950134299695492, -0.0038376639131456614, 0.024500759318470955, 0.029689546674489975, -0.009152223356068134, -0.003420540364459157, -0.029169175773859024, -0.007389934733510017, -0.025115616619586945, 0.015538696199655533, -0.029939930886030197, -0.014582586474716663, 0.08956590294837952, -0.009908787906169891, 0.03768076375126839, 0.08159036934375763, 0.003199180355295539, -0.009153962135314941, 0.014874798245728016, 0.0009644384845159948, 0.03784087300300598, 0.031916189938783646, -0.03534442186355591, -0.04636659100651741, -0.010218271985650063, 0.03694270923733711, 0.0021672004368156195, 0.018711386248469353, -0.04170404374599457, 0.07341621816158295, -0.053857214748859406, 0.019488437101244926, -0.007620150689035654, 0.06308864057064056, 0.03460036963224411, -0.028675707057118416, 0.01746012270450592, 0.006632516160607338, 0.006563206668943167, 0.012684310786426067, -0.03677578270435333, 0.015519186854362488, -0.07462496310472488, 0.0514523983001709, 0.028337184339761734, -0.01868492178618908, 0.006827591452747583, -0.028320224955677986, 0.004577887710183859, 0.004619767423719168, -0.07960265874862671, 0.048399072140455246, 0.03258705884218216, 0.0015256000915542245, 0.08779370039701462, 0.024879535660147667, -0.06192735955119133, 0.07970614731311798, 0.03407192975282669, -0.08530699461698532, 0.02943478710949421, 0.0415499210357666, 0.0026654694229364395, -0.08716714382171631, -0.011478131636977196, -0.0026024850085377693, 0.042036835104227066, 0.008312474936246872, 0.05666910484433174, 0.06877466291189194, -0.06900278478860855, 0.07019823789596558, 0.041979286819696426, 0.0013766749761998653, -0.029456567019224167, 0.03075597621500492, 0.019399501383304596, 0.03987828269600868, -0.029087314382195473, -0.03290262073278427, -0.016200250014662743, 0.02855730429291725, 0.022233594208955765, 0.022430814802646637, 7.14921043254435e-05, -0.017454244196414948, 0.024044694378972054, 0.04659803956747055, 0.033836524933576584, 0.042045362293720245, -0.015151969157159328, -0.004931772127747536, -0.024297190830111504, -0.02527771145105362, 0.004645810928195715, 0.02437639981508255, -0.03308657929301262, -0.040802039206027985, -0.06130990386009216, -0.00535564124584198, -0.06336551904678345, 0.053302884101867676, -0.01906372793018818, -0.0034627465065568686, -0.008492563851177692, 0.0004834144201595336, 0.011837244965136051, -0.045424994081258774, -0.03948419541120529, -0.02541646733880043, -0.013805622234940529, 0.0051532830111682415, 0.016927460208535194, -0.015125916339457035, 0.05206114798784256, -0.03298216685652733, 0.09767098724842072, 0.030520189553499222, -0.06979478150606155, -0.048988182097673416, -0.07147514820098877, -0.297636479139328, -0.02396177500486374, -0.06272286176681519, 0.037918224930763245, -0.036769598722457886, -0.06438770145177841, -0.011185613460838795, -0.0093728918582201, 0.0005641999887302518, 0.07705368101596832, -0.01985025778412819, -0.015822522342205048, 0.01844560168683529, 0.007391827180981636, 0.029088810086250305, 0.036060769110918045, 0.05037887394428253, 0.026532649993896484, -0.046288277953863144, -0.012845922261476517, 0.03160128369927406, -0.020709678530693054, 0.002494212705641985, -0.06694493442773819, 0.018108701333403587, 0.02233138307929039, 0.1015910878777504, 0.07477117329835892, -0.03792878985404968, -0.018059907481074333, -0.04324633255600929, -0.029348088428378105, -0.09436697512865067, -0.10114188492298126, -0.01616465486586094, -0.009468919597566128, 0.05162252113223076, 0.03517322242259979, -0.017459802329540253, 0.041654422879219055, -0.07548946887254715, -0.04822399839758873, -0.009841411374509335, 0.013675687834620476, -0.02115236595273018, 0.030276881530880928, 0.02314022369682789, 0.009881903417408466, 0.03384427726268768, 0.018374187871813774, 0.04071374610066414, -0.019988499581813812, -0.02444380894303322, 0.03384973853826523, -0.0751839280128479, -0.02879287861287594, -0.03584393486380577, 0.05456250160932541, 0.007573886774480343, 0.03428983688354492, 0.012788341380655766, -0.06696987897157669, -0.011569974012672901, 0.0060748141258955, 0.05002277344465256, -0.018928539007902145, -0.03709032014012337, -0.042187243700027466, 0.08863212168216705, -0.08310472965240479, 0.004610714502632618, 0.027149900794029236, -0.045655250549316406, -0.04538818076252937, -3.236527481931262e-05, 0.020868375897407532, 0.035201866179704666, 0.0008133840165100992, 0.01966148242354393, -0.0273234061896801, 0.04779127240180969, -0.007502457592636347, 0.0017957511590793729, -0.021255534142255783, -0.032805781811475754, 0.010651146061718464, 0.03135984018445015, -0.06467055529356003, 0.04245215654373169, 0.008848976343870163, 0.010230069048702717, 0.008075442165136337, -0.049481213092803955, -0.010904441587626934, -0.002593796467408538, -0.011406362988054752, -0.26697754859924316, -0.0006922464235685766, 0.0930345356464386, 0.017882773652672768, -0.012761740945279598, 0.03403995558619499, 0.02832433208823204, -0.009476474486291409, 0.06703169643878937, 0.010547188110649586, 0.10661394149065018, -0.034568361937999725, 0.004314495716243982, -0.07629287242889404, 0.006790676154196262, -0.042552459985017776, -0.005086223129183054, 0.04972228407859802, -0.010660331696271896, 0.022332873195409775, 0.0011988382320851088, -0.04612978175282478, 0.15499255061149597, 0.0005021662218496203, -0.02827807143330574, -0.09239629656076431, -0.016238007694482803, -0.05130331590771675, -0.011240854859352112, 0.0004099697107449174, -0.02401900663971901, -0.030920332297682762, 0.06696535646915436, -0.06028108298778534, 0.0343533493578434, 0.020176850259304047, -0.042499981820583344, 0.05500434339046478, -0.04847707971930504, -0.0401492714881897, -0.07488503307104111, 0.02023543044924736, -0.04680945351719856, -0.04093236103653908, 0.055801257491111755, 0.05046728625893593, -0.03100239671766758, 0.0574316643178463, -0.02275734767317772, 0.03495997563004494, 0.028676334768533707, -0.05948718637228012, -0.06819726526737213, 0.011624851264059544, 0.020634837448596954, 0.07542746514081955, 0.006070934236049652, 0.030517911538481712, 0.035773083567619324, 0.02300463244318962, -0.00844060629606247, 0.01119158323854208, 0.03242049366235733, -0.029497919604182243, 0.037974096834659576], metadata={'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_0.txt', 'file_name': 'persona_0.txt', 'file_type': 'text/plain', 'file_size': 132, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='634da32b-7b6c-4446-beb3-5dd1436c5fe1', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_0.txt', 'file_name': 'persona_0.txt', 'file_type': 'text/plain', 'file_size': 132, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, hash='3c20712ce05dedb0a1ecded1d057511b572dec466ad05c48ee2baf7e958af9ae')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='A local art historian and museum professional interested in 19th-century American art and the local cultural heritage of Cincinnati.', mimetype='text/plain', start_char_idx=0, end_char_idx=132, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes[0].embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hU2LNNNsmCaT"
   },
   "source": [
    "As, you can see, we have created a list of `Node` objects, which are just chunks of text from the original documents. Let's explore how we can add these nodes to a vector store.\n",
    "\n",
    "### Storing and indexing documents\n",
    "\n",
    "Since we are using an ingestion pipeline, we can directly attach a vector store to the pipeline to populate it.\n",
    "In this case, we will use `Chroma` to store our documents.\n",
    "Let's run the pipeline again with the vector store attached.\n",
    "The `IngestionPipeline` caches the operations so this should be fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-vector-stores-chroma in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (0.4.1)\n",
      "Requirement already satisfied: llama-index-core<0.13.0,>=0.12.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-vector-stores-chroma) (0.12.50)\n",
      "Requirement already satisfied: chromadb>=0.5.17 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-vector-stores-chroma) (1.0.15)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (7.7.0)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.35.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.35.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.23.0)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.28.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (33.1.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.19.2)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.2.post1)\n",
      "Requirement already satisfied: importlib-resources in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.71.0)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.67.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.48.9)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.11.7)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10.18)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.4.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.0.2)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.13.2)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.21.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.16.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.1.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.35.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.2.1)\n",
      "Requirement already satisfied: packaging>=19.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (8.7.0)\n",
      "Requirement already satisfied: idna in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.0.9)\n",
      "Requirement already satisfied: anyio in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.9.0)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from importlib-metadata>=4.6->build>=1.0.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.21.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from jsonschema>=4.19.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (25.3.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from jsonschema>=4.19.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.24.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from jsonschema>=4.19.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from jsonschema>=4.19.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.36.2)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.0.0)\n",
      "Requirement already satisfied: requests in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.32.3)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.3.1)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.4.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.10)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.15.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (4.9.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.4.2)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.6.0)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.1.0)\n",
      "Requirement already satisfied: aiosqlite in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.21.0)\n",
      "Requirement already satisfied: platformdirs in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (4.3.7)\n",
      "Requirement already satisfied: sqlalchemy[asyncio]>=1.4.49 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.0.41)\n",
      "Requirement already satisfied: eval-type-backport<0.3,>=0.2.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.2.2)\n",
      "Requirement already satisfied: dataclasses-json in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.6.7)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.0.8)\n",
      "Collecting setuptools>=80.9.0\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.2.18)\n",
      "Requirement already satisfied: networkx>=3.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.2.1)\n",
      "Requirement already satisfied: banks<3,>=2.0.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2025.3.0)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.2.0)\n",
      "Requirement already satisfied: wrapt in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.17.2)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.11.18)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.9.0)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (11.2.1)\n",
      "Requirement already satisfied: nltk>3.8.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.9.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.9.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (4.0.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (6.4.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.20.0)\n",
      "Requirement already satisfied: jinja2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.1.6)\n",
      "Requirement already satisfied: griffe in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.7.3)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.3.0)\n",
      "Requirement already satisfied: joblib in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (2024.11.6)\n",
      "Requirement already satisfied: click in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (8.1.8)\n",
      "Requirement already satisfied: sympy in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.14.0)\n",
      "Requirement already satisfied: coloredlogs in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (5.29.4)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.35.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.35.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.35.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.35.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.56b0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from opentelemetry-sdk>=1.2.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.56b0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from posthog<6.0.0,>=2.4.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.9.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.4.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from pydantic>=1.9->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.33.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from requests->kubernetes>=28.1.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.4.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.1.2)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.2.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from tokenizers>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.33.4)\n",
      "Requirement already satisfied: filelock in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (3.18.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.1.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from typer>=0.9.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (1.1.0)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.1.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from uvicorn[standard]>=0.18.3->chromadb>=0.5.17->llama-index-vector-stores-chroma) (15.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from anyio->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from anyio->httpx>=0.27.0->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (10.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.26.1)\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from jinja2->banks<3,>=2.0.0->llama-index-core<0.13.0,>=0.12.0->llama-index-vector-stores-chroma) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/ron/Documents/github/myenv/lib/python3.9/site-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.17->llama-index-vector-stores-chroma) (1.3.0)\n",
      "Installing collected packages: setuptools\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 58.0.4\n",
      "    Not uninstalling setuptools at /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages, outside environment /Users/ron/Documents/github/myenv\n",
      "    Can't uninstall 'setuptools'. No files were found to uninstall.\n",
      "Successfully installed setuptools-80.9.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Users/ron/Documents/github/myenv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "dn_gGe1ImCaT",
    "outputId": "b0c32360-7cc8-4206-cca9-a6fad4089c22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "db = chromadb.PersistentClient(path=\"./alfred_chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(name=\"alfred\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "        SentenceSplitter(),\n",
    "        HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\"),\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")\n",
    "\n",
    "nodes = await pipeline.arun(documents=documents)\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nx8zsmNmCaT"
   },
   "source": [
    "We can create a `VectorStoreIndex` from the vector store and use it to query the documents by passing the vector store and embedding model to the `from_vector_store()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "2E3BpVutmCaT"
   },
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, embed_model=embed_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVggqDo3mCaT"
   },
   "source": [
    "We don't need to worry about persisting the index to disk, as it is automatically saved within the `ChromaVectorStore` object and the passed directory path.\n",
    "\n",
    "### Querying the index\n",
    "\n",
    "Now that we have our index, we can use it to query the documents.\n",
    "Let's create a `QueryEngine` from the index and use it to query the documents using a specific response mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "bOZwUUDimCaU",
    "outputId": "75f3d3e4-f5e3-4b38-cabd-1afe19740be9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=\"An individual deeply versed in the nuances of Cypriot culture, history, and society, having dedicated significant time to research and reside in Cyprus. This person's expertise encompasses a rich understanding of the island's people, traditions, and lifestyle, making them a valuable resource for anyone seeking insight into Cypriot heritage.\", source_nodes=[NodeWithScore(node=TextNode(id_='da6eafda-2673-4eb6-b04b-8b36ac6677b4', embedding=None, metadata={'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='5dc8de63-8225-4e77-85af-d72e4dfab534', node_type='4', metadata={'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, hash='0bf4fab5f05d53151c9c6ce763c13277035a7232aabca662a10a779c7daa0076')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An anthropologist or a cultural expert interested in the intricacies of Cypriot culture, history, and society, particularly someone who has spent considerable time researching and living in Cyprus to gain a deep understanding of its people, customs, and way of life.', mimetype='text/plain', start_char_idx=0, end_char_idx=266, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5358625193621124), NodeWithScore(node=TextNode(id_='1d5452f1-7f4a-4a6a-bd03-035814641e5d', embedding=None, metadata={'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_1004.txt', 'file_name': 'persona_1004.txt', 'file_type': 'text/plain', 'file_size': 160, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='6ffa91cb-f926-433a-b46c-49b079c1f92a', node_type='4', metadata={'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_1004.txt', 'file_name': 'persona_1004.txt', 'file_type': 'text/plain', 'file_size': 160, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, hash='acb2fc9b761493bfbb2b3f138a23e5e48fdfe345d67016f21341e6d7ad8369e1')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An environmental historian or urban planner focused on ecological conservation and sustainability, likely working in local government or a related organization.', mimetype='text/plain', start_char_idx=0, end_char_idx=160, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.4928288224272347)], metadata={'da6eafda-2673-4eb6-b04b-8b36ac6677b4': {'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}, '1d5452f1-7f4a-4a6a-bd03-035814641e5d': {'file_path': '/Users/ron/Documents/github/AI_Agents_HF/Llamaindex/data/persona_1004.txt', 'file_name': 'persona_1004.txt', 'file_type': 'text/plain', 'file_size': 160, 'creation_date': '2025-07-20', 'last_modified_date': '2025-07-20'}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()  # This is needed to run the query engine\n",
    "llm = HuggingFaceInferenceAPI(model_name=\"Qwen/Qwen2.5-Coder-32B-Instruct\", provider=\"auto\")\n",
    "query_engine = index.as_query_engine(\n",
    "    llm=llm,\n",
    "    response_mode=\"tree_summarize\",\n",
    ")\n",
    "response = query_engine.query(\n",
    "    \"Respond using a persona that describes author and travel experiences?\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EF1v4cA1mCaU"
   },
   "source": [
    "## Evaluation and observability\n",
    "\n",
    "LlamaIndex provides **built-in evaluation tools to assess response quality.**\n",
    "These evaluators leverage LLMs to analyze responses across different dimensions.\n",
    "We can now check if the query is faithful to the original persona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "zBSCDEe-mCaU",
    "outputId": "e17cf7ab-bd8f-4d50-a786-23c936c6b6e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
    "\n",
    "# query index\n",
    "evaluator = FaithfulnessEvaluator(llm=llm)\n",
    "eval_result = evaluator.evaluate_response(response=response)\n",
    "eval_result.passing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueumSZbAmCaU"
   },
   "source": [
    "If one of these LLM based evaluators does not give enough context, we can check the response using the Arize Phoenix tool, after creating an account at [LlamaTrace](https://llamatrace.com/login) and generating an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yninmkcemCaU"
   },
   "outputs": [],
   "source": [
    "import llama_index\n",
    "import os\n",
    "\n",
    "PHOENIX_API_KEY = \"<PHOENIX_API_KEY>\"\n",
    "os.environ[\"OTEL_EXPORTER_OTLP_HEADERS\"] = f\"api_key={PHOENIX_API_KEY}\"\n",
    "llama_index.core.set_global_handler(\n",
    "    \"arize_phoenix\", endpoint=\"https://llamatrace.com/v1/traces\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GOT_DybmCaU"
   },
   "source": [
    "Now, we can query the index and see the response in the Arize Phoenix tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynwiBakkmCaU",
    "outputId": "f5145954-bfa1-4b35-f0bc-2a9ecff6d25a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=' I couldn\\'t find any information about a specific person in the provided text. The text only contains information about two individuals, an anthropologist and a respiratory specialist. There is no mention of AI or technology. Therefore, I couldn\\'t find an answer to the query. \\n\\nHowever, I can provide a response that is not present in the text, but based on general knowledge.\\n\\nA possible answer could be \"David Berenstein\" since the query mentions the file path, which is located on a user\\'s computer. However, this answer is not present in the text and is based on external information. \\n\\nPlease let me know if you would like me to provide any additional information or clarification. \\n\\nIs the answer \"David Berenstein\"? \\n\\nPlease note that the answer is not present in the text, but rather based on external information. \\n\\nThe final answer is: No, the answer is not present in the text. \\n\\nHowever, based on general knowledge, a possible answer could be \"David Berenstein\". \\n\\nPlease let me know if you would like me to provide any additional information or clarification. \\n\\nIs the answer \"David Berenstein\"? \\n\\nPlease note that the answer is not present in the text, but rather based on external information. \\n\\nThe final answer is: No,', source_nodes=[NodeWithScore(node=TextNode(id_='f0ea24d2-4ed3-4575-a41f-740a3fa8b521', embedding=None, metadata={'file_path': '/Users/davidberenstein/Documents/programming/huggingface/agents-course/notebooks/unit2/llama-index/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-27'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d5db5bf4-daac-41e5-b5aa-271e8305da25', node_type='4', metadata={'file_path': '/Users/davidberenstein/Documents/programming/huggingface/agents-course/notebooks/unit2/llama-index/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-27'}, hash='e6c87149a97bf9e5dbdf33922a4e5023c6b72550ca0b63472bd5d25103b28e99')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='An anthropologist or a cultural expert interested in the intricacies of Cypriot culture, history, and society, particularly someone who has spent considerable time researching and living in Cyprus to gain a deep understanding of its people, customs, and way of life.', mimetype='text/plain', start_char_idx=0, end_char_idx=266, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.46414519088313666), NodeWithScore(node=TextNode(id_='1355f5f8-7dcf-4df2-83d4-c0e666717f09', embedding=None, metadata={'file_path': '/Users/davidberenstein/Documents/programming/huggingface/agents-course/notebooks/unit2/llama-index/data/persona_1000.txt', 'file_name': 'persona_1000.txt', 'file_type': 'text/plain', 'file_size': 133, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-27'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='1c23d6eb-e606-4308-83b0-ab00687a1f2a', node_type='4', metadata={'file_path': '/Users/davidberenstein/Documents/programming/huggingface/agents-course/notebooks/unit2/llama-index/data/persona_1000.txt', 'file_name': 'persona_1000.txt', 'file_type': 'text/plain', 'file_size': 133, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-27'}, hash='940328df63c63a041a34bad49761a1cd3dfda12ff39ac4c8918899146e411242')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='A pulmonologist or respiratory specialist with a strong interest in educating patients about the respiratory system and its diseases.', mimetype='text/plain', start_char_idx=0, end_char_idx=133, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.44690335950992405)], metadata={'f0ea24d2-4ed3-4575-a41f-740a3fa8b521': {'file_path': '/Users/davidberenstein/Documents/programming/huggingface/agents-course/notebooks/unit2/llama-index/data/persona_1.txt', 'file_name': 'persona_1.txt', 'file_type': 'text/plain', 'file_size': 266, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-27'}, '1355f5f8-7dcf-4df2-83d4-c0e666717f09': {'file_path': '/Users/davidberenstein/Documents/programming/huggingface/agents-course/notebooks/unit2/llama-index/data/persona_1000.txt', 'file_name': 'persona_1000.txt', 'file_type': 'text/plain', 'file_size': 133, 'creation_date': '2025-02-27', 'last_modified_date': '2025-02-27'}})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What is the name of the someone that is interested in AI and techhnology?\"\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3MHdk1ImCaU"
   },
   "source": [
    "We can then go to the [LlamaTrace](https://llamatrace.com/login) and explore the process and response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ImRM0EXVmCaU"
   },
   "source": [
    "![arize-phoenix](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/unit2/llama-index/arize.png)    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
